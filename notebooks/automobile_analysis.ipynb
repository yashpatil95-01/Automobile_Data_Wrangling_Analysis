{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Automobile Data Wrangling and Analysis\n",
    "\n",
    "This notebook performs comprehensive analysis of automobile data including:\n",
    "- Data loading and cleaning\n",
    "- Exploratory data analysis\n",
    "- Statistical analysis and correlations\n",
    "- Advanced visualizations\n",
    "- Feature engineering\n",
    "- Missing data analysis\n",
    "\n",
    "**Author:** Yash Patil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create organized results directories\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "results_dir = os.path.join(base_dir, \"results\")\n",
    "viz_dir = os.path.join(results_dir, \"visualizations\")\n",
    "data_dir = os.path.join(results_dir, \"processed_data\")\n",
    "reports_dir = os.path.join(results_dir, \"reports\")\n",
    "\n",
    "for directory in [results_dir, viz_dir, data_dir, reports_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Results will be saved to: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_automobile_data():\n",
    "    \"\"\"Load automobile dataset from UCI repository.\"\"\"\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "    \n",
    "    # Column names based on UCI dataset documentation\n",
    "    column_names = [\n",
    "        \"symboling\", \"normalized-losses\", \"make\", \"fuel-type\", \"aspiration\", \n",
    "        \"num-of-doors\", \"body-style\", \"drive-wheels\", \"engine-location\",\n",
    "        \"wheel-base\", \"length\", \"width\", \"height\", \"curb-weight\", \n",
    "        \"engine-type\", \"num-of-cylinders\", \"engine-size\", \"fuel-system\", \n",
    "        \"bore\", \"stroke\", \"compression-ratio\", \"horsepower\", \"peak-rpm\", \n",
    "        \"city-mpg\", \"highway-mpg\", \"price\"\n",
    "    ]\n",
    "    \n",
    "    df = pd.read_csv(url, header=None, names=column_names)\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "df = load_automobile_data()\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {len(df.columns)} features\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_cleaning",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"Original data info:\")\n",
    "print(f\"Shape: {df_clean.shape}\")\n",
    "print(f\"Data types: {df_clean.dtypes.value_counts()}\")\n",
    "\n",
    "# Check for missing values represented as '?'\n",
    "print(\"\\nColumns with '?' values:\")\n",
    "for col in df_clean.columns:\n",
    "    question_count = (df_clean[col] == '?').sum()\n",
    "    if question_count > 0:\n",
    "        print(f\"{col}: {question_count} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '?' with NaN\n",
    "df_clean = df_clean.replace('?', np.nan)\n",
    "\n",
    "# Convert numeric columns\n",
    "numeric_columns = [\n",
    "    'symboling', 'normalized-losses', 'wheel-base', 'length', 'width', \n",
    "    'height', 'curb-weight', 'engine-size', 'bore', 'stroke', \n",
    "    'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', \n",
    "    'highway-mpg', 'price'\n",
    "]\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "# Convert fuel efficiency from MPG to L/100km for international standard\n",
    "df_clean['city-L/100km'] = 235 / df_clean['city-mpg']\n",
    "df_clean['highway-L/100km'] = 235 / df_clean['highway-mpg']\n",
    "\n",
    "# Create price categories\n",
    "df_clean['price_category'] = pd.cut(df_clean['price'], \n",
    "                                   bins=[0, 10000, 20000, 50000], \n",
    "                                   labels=['Budget', 'Mid-range', 'Luxury'])\n",
    "\n",
    "print(\"Data cleaning completed!\")\n",
    "print(f\"Final shape: {df_clean.shape}\")\n",
    "print(f\"\\nMissing values per column:\")\n",
    "missing_summary = df_clean.isnull().sum().sort_values(ascending=False)\n",
    "print(missing_summary[missing_summary > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic_eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "numerical_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(f\"Dataset Overview:\")\n",
    "print(f\"Shape: {df_clean.shape}\")\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")\n",
    "print(f\"Numerical columns: {len(numerical_cols)}\")\n",
    "\n",
    "# Show top categorical summaries\n",
    "for col in ['make', 'body-style', 'fuel-type']:\n",
    "    print(f\"\\n{col.upper()} - Top 5:\")\n",
    "    print(df_clean[col].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key numerical features summary\n",
    "key_features = ['price', 'horsepower', 'engine-size', 'city-mpg', 'highway-mpg']\n",
    "print(\"Key Numerical Features Summary:\")\n",
    "df_clean[key_features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualizations",
   "metadata": {},
   "source": [
    "## 5. Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic analysis visualizations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "df_clean['price'].dropna().hist(bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Price Distribution')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "make_counts = df_clean['make'].value_counts().head(8)\n",
    "make_counts.plot(kind='bar')\n",
    "plt.title('Top 8 Car Makes')\n",
    "plt.xlabel('Make')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "df_clean['body-style'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Body Style Distribution')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "df_clean.boxplot(column='price', ax=plt.gca())\n",
    "plt.title('Price Box Plot')\n",
    "plt.ylabel('Price ($)')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "df_clean['fuel-type'].value_counts().plot(kind='bar', color=['skyblue', 'lightcoral'])\n",
    "plt.title('Fuel Type Distribution')\n",
    "plt.xlabel('Fuel Type')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "df_clean.plot.scatter(x='engine-size', y='price', alpha=0.6, ax=plt.gca())\n",
    "plt.title('Engine Size vs Price')\n",
    "plt.xlabel('Engine Size')\n",
    "plt.ylabel('Price ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(viz_dir, 'basic_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis with price\n",
    "price_data = df_clean.dropna(subset=['price'])\n",
    "correlations = []\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col != 'price' and col in price_data.columns:\n",
    "        valid_data = price_data[[col, 'price']].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_coef = valid_data[col].corr(valid_data['price'])\n",
    "            correlations.append({\n",
    "                'Feature': col,\n",
    "                'Correlation': corr_coef,\n",
    "                'Abs_Correlation': abs(corr_coef)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Abs_Correlation', ascending=False)\n",
    "\n",
    "print(\"Top 10 correlations with price:\")\n",
    "print(corr_df.head(10))\n",
    "\n",
    "# Visualize top correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_corr = corr_df.head(8)\n",
    "colors = ['red' if x < 0 else 'blue' for x in top_corr['Correlation']]\n",
    "plt.barh(range(len(top_corr)), top_corr['Correlation'], color=colors, alpha=0.7)\n",
    "plt.yticks(range(len(top_corr)), top_corr['Feature'])\n",
    "plt.xlabel('Correlation with Price')\n",
    "plt.title('Top Feature Correlations with Price')\n",
    "plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(viz_dir, 'price_correlations.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insights",
   "metadata": {},
   "source": [
    "## 6. Key Business Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "business_insights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate business insights\n",
    "insights = []\n",
    "\n",
    "# Price insights\n",
    "avg_price = df_clean['price'].mean()\n",
    "median_price = df_clean['price'].median()\n",
    "insights.append(f\"Average car price: ${avg_price:,.2f}\")\n",
    "insights.append(f\"Median car price: ${median_price:,.2f}\")\n",
    "\n",
    "# Top correlation\n",
    "if len(corr_df) > 0:\n",
    "    top_corr = corr_df.iloc[0]\n",
    "    insights.append(f\"Strongest price predictor: {top_corr['Feature']} (r = {top_corr['Correlation']:.3f})\")\n",
    "\n",
    "# Market insights\n",
    "most_common_make = df_clean['make'].mode()[0]\n",
    "make_count = df_clean['make'].value_counts().iloc[0]\n",
    "insights.append(f\"Most common make: {most_common_make} ({make_count} cars)\")\n",
    "\n",
    "# Performance insights\n",
    "avg_horsepower = df_clean['horsepower'].mean()\n",
    "if not np.isnan(avg_horsepower):\n",
    "    insights.append(f\"Average horsepower: {avg_horsepower:.0f} HP\")\n",
    "\n",
    "print(\"Key Business Insights:\")\n",
    "print(\"=\" * 50)\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"{i}. {insight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_export",
   "metadata": {},
   "source": [
    "## 7. Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed datasets\n",
    "print(\"Saving processed data...\")\n",
    "\n",
    "# Save cleaned dataset\n",
    "df_clean.to_csv(os.path.join(data_dir, 'automobile_data_cleaned.csv'), index=False)\n",
    "\n",
    "# Save correlation analysis\n",
    "corr_df.to_csv(os.path.join(reports_dir, 'price_correlations.csv'), index=False)\n",
    "\n",
    "# Save summary statistics\n",
    "df_clean.describe().to_csv(os.path.join(reports_dir, 'numeric_summary.csv'))\n",
    "\n",
    "print(\"Files saved to organized directories:\")\n",
    "print(f\"- Processed data: {data_dir}/\")\n",
    "print(f\"- Reports: {reports_dir}/\")\n",
    "print(f\"- Visualizations: {viz_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Analysis Complete!\n",
    "\n",
    "This comprehensive automobile data analysis has provided:\n",
    "\n",
    "### Data Quality\n",
    "- Successfully processed 205 automobile records\n",
    "- Handled missing values and data type conversions\n",
    "- Created meaningful feature categories\n",
    "\n",
    "### Key Findings\n",
    "- Identified strongest predictors of automobile price\n",
    "- Analyzed market distribution across makes and body styles\n",
    "- Quantified performance relationships\n",
    "\n",
    "### Outputs\n",
    "All results are organized in the `results/` directory:\n",
    "- **visualizations/**: Charts and plots\n",
    "- **processed_data/**: Clean datasets\n",
    "- **reports/**: Analysis summaries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}